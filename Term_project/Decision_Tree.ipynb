{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydotplus \n",
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import _pickle as cPickle\n",
    "from scipy.stats import kurtosis, skew\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "- Two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    result = []\n",
    "    mean = np.mean(data)\n",
    "    median = np.median(data)\n",
    "    maximum = np.amax(data)\n",
    "    minimum = np.amin(data)\n",
    "    std_dev = np.std(data)\n",
    "    var = np.var(data)\n",
    "    ran = np.ptp(data)\n",
    "    skewness = skew(data)\n",
    "    kurto = kurtosis(data)\n",
    "    result=[mean, median, maximum, minimum,\n",
    "                   std_dev, var, ran, skewness, kurto]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirname = './data_preprocessed_python'\n",
    "filenames = os.listdir(dirname)\n",
    "data_dic = defaultdict(lambda:[])\n",
    "for i, filename in enumerate(filenames):\n",
    "    full_filename = os.path.join(dirname, filename)\n",
    "    x = cPickle.load(open(full_filename, 'rb'), encoding='ISO-8859-1')\n",
    "    data_dic[filename[:-4]] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_data_dic = defaultdict(lambda:defaultdict(lambda:[]))\n",
    "for key in data_dic.keys():\n",
    "    par = int(key[1:])\n",
    "    \n",
    "    for i, vid in enumerate(data_dic[key]['data']):\n",
    "        new_data_dic[key]['data'].append([])\n",
    "        for chnn in vid[:-8]:\n",
    "            l =preprocessing(np.array(chnn))\n",
    "            for batch in range(0,10):\n",
    "                l = l+preprocessing(np.array(chnn[batch*807:max((batch+1)*807, 8064)]))\n",
    "            new_data_dic[key]['data'][i].append(np.array([par, i+1]+l))\n",
    "    for i,  vid in enumerate(data_dic[key]['labels']):\n",
    "        l2 = []\n",
    "        new_data_dic[key]['labels'].append([])\n",
    "        for value in vid:\n",
    "            if value>=5:\n",
    "                l2.append(1)\n",
    "            else:\n",
    "                l2.append(0)\n",
    "        new_data_dic[key]['labels'][i] += l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Train_data and Test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process s06\n",
      "process s18\n",
      "process s27\n",
      "process s07\n",
      "process s15\n",
      "process s10\n",
      "process s08\n",
      "process s02\n",
      "process s31\n",
      "process s16\n",
      "process s28\n",
      "process s14\n",
      "process s32\n",
      "process s23\n",
      "process s09\n",
      "process s22\n",
      "process s29\n",
      "process s24\n",
      "process s13\n",
      "process s04\n",
      "process s19\n",
      "process s01\n",
      "process s12\n",
      "process s20\n",
      "process s11\n",
      "process s26\n",
      "process s03\n",
      "process s21\n",
      "process s25\n",
      "process s30\n",
      "process s17\n",
      "process s05\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "train_label = []\n",
    "test_data = []\n",
    "test_label = []\n",
    "for i in new_data_dic:\n",
    "    print(\"process {}\".format(i))\n",
    "    if i != 's02':\n",
    "        \n",
    "        for j in range(len(new_data_dic[i]['labels'])):\n",
    "            temp = np.array(new_data_dic[i]['data'][j]).reshape(-1, 32*101)[0]\n",
    "            train_data.append(temp)\n",
    "            train_label.append(new_data_dic[i]['labels'][j])\n",
    "    else:\n",
    "        for j in range(len(new_data_dic[i]['labels'])):\n",
    "            temp = np.array(new_data_dic[i]['data'][j]).reshape(-1, 32*101)[0]\n",
    "            test_data.append(temp)\n",
    "            test_label.append(new_data_dic[i]['labels'][j])\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define decision tree model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "# fit it to our data\n",
    "dt.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is: 49.375%\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(len(test_data)):\n",
    "    result.append(dt.predict(test_data[i].reshape(1,-1))[0])\n",
    "\n",
    "count = 0\n",
    "for index, i in enumerate(result):\n",
    "    for j in range(len(i)):\n",
    "        if(i[j]==test_label[index][j]):\n",
    "            count += 1\n",
    "print(\"The Accuracy is: {}%\".format(count/(len(test_label)*4) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "- Three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_data_dic_3 = defaultdict(lambda:defaultdict(lambda:[]))\n",
    "for key in data_dic.keys():\n",
    "    par = int(key[1:])\n",
    "    \n",
    "    for i, vid in enumerate(data_dic[key]['data']):\n",
    "        new_data_dic_3[key]['data'].append([])\n",
    "        for chnn in vid[:-8]:\n",
    "            l =preprocessing(np.array(chnn))\n",
    "            for batch in range(0,10):\n",
    "                l = l+preprocessing(np.array(chnn[batch*807:max((batch+1)*807, 8064)]))\n",
    "            new_data_dic_3[key]['data'][i].append(np.array([par, i+1]+l))\n",
    "    for i,  vid in enumerate(data_dic[key]['labels']):\n",
    "        l2 = []\n",
    "        new_data_dic_3[key]['labels'].append([])\n",
    "        for value in vid:\n",
    "            if value>=6:\n",
    "                l2.append(2)\n",
    "            if value<6 and value >= 4:\n",
    "                l2.append(1)\n",
    "            if value < 4:\n",
    "                l2.append(0)\n",
    "        new_data_dic_3[key]['labels'][i] += l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process s06\n",
      "process s18\n",
      "process s27\n",
      "process s07\n",
      "process s15\n",
      "process s10\n",
      "process s08\n",
      "process s02\n",
      "process s31\n",
      "process s16\n",
      "process s28\n",
      "process s14\n",
      "process s32\n",
      "process s23\n",
      "process s09\n",
      "process s22\n",
      "process s29\n",
      "process s24\n",
      "process s13\n",
      "process s04\n",
      "process s19\n",
      "process s01\n",
      "process s12\n",
      "process s20\n",
      "process s11\n",
      "process s26\n",
      "process s03\n",
      "process s21\n",
      "process s25\n",
      "process s30\n",
      "process s17\n",
      "process s05\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "train_data_3 = []\n",
    "train_label_3 = []\n",
    "test_data_3 = []\n",
    "test_label_3 = []\n",
    "for i in new_data_dic:\n",
    "    print(\"process {}\".format(i))\n",
    "    if i != 's02':\n",
    "        for j in range(len(new_data_dic_3[i]['labels'])):\n",
    "            temp = np.array(new_data_dic_3[i]['data'][j]).reshape(-1, 32*101)[0]\n",
    "            train_data_3.append(temp)\n",
    "            train_label_3.append(new_data_dic_3[i]['labels'][j])\n",
    "    else:\n",
    "        for j in range(len(new_data_dic_3[i]['labels'])):\n",
    "            temp = np.array(new_data_dic_3[i]['data'][j]).reshape(-1, 32*101)[0]\n",
    "            test_data_3.append(temp)\n",
    "            test_label_3.append(new_data_dic_3[i]['labels'][j])\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also, Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_3 = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "# fit it to our data\n",
    "dt_3.fit(train_data_3, train_label_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is: 30.625000000000004%\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(len(test_data_3)):\n",
    "#     print(dt_3.predict(test_data_3[i].reshape(1,-1))[0])\n",
    "    result.append(dt_3.predict(test_data_3[i].reshape(1,-1))[0])\n",
    "\n",
    "count = 0\n",
    "for index, i in enumerate(result):\n",
    "    for j in range(len(i)):\n",
    "        if(i[j]==test_label_3[index][j]):\n",
    "            count += 1\n",
    "print(\"The Accuracy is: {}%\".format(count/(len(test_label_3)*4) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "- Two classes classification Accuracy is : 49%~57%\n",
    "- Three classes classification Accuracy is : 30%~42%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
