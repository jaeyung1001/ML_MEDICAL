{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pydotplus \n",
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import _pickle as cPickle\n",
    "from scipy.stats import kurtosis, skew\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    result = []\n",
    "    mean = np.mean(data)\n",
    "    median = np.median(data)\n",
    "    maximum = np.amax(data)\n",
    "    minimum = np.amin(data)\n",
    "    std_dev = np.std(data)\n",
    "    var = np.var(data)\n",
    "    ran = np.ptp(data)\n",
    "    skewness = skew(data)\n",
    "    kurto = kurtosis(data)\n",
    "    result=[mean, median, maximum, minimum,\n",
    "                   std_dev, var, ran, skewness, kurto]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirname = './data_preprocessed_python'\n",
    "filenames = os.listdir(dirname)\n",
    "data_dic = defaultdict(lambda:[])\n",
    "for i, filename in enumerate(filenames):\n",
    "    full_filename = os.path.join(dirname, filename)\n",
    "    x = cPickle.load(open(full_filename, 'rb'), encoding='ISO-8859-1')\n",
    "    data_dic[filename[:-4]] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_dic = defaultdict(lambda:defaultdict(lambda:[]))\n",
    "for key in data_dic.keys():\n",
    "    par = int(key[1:])\n",
    "    \n",
    "    for i, vid in enumerate(data_dic[key]['data']):\n",
    "        new_data_dic[key]['data'].append([])\n",
    "        for chnn in vid[:-8]:\n",
    "            l =preprocessing(np.array(chnn))\n",
    "            for batch in range(0,10):\n",
    "                l = l+preprocessing(np.array(chnn[batch*807:max((batch+1)*807, 8064)]))\n",
    "            new_data_dic[key]['data'][i].append(np.array([par, i+1]+l))\n",
    "    for i,  vid in enumerate(data_dic[key]['labels']):\n",
    "        l2 = []\n",
    "        new_data_dic[key]['labels'].append([])\n",
    "        for value in vid:\n",
    "            if value>=5:\n",
    "                l2.append(1)\n",
    "            else:\n",
    "                l2.append(0)\n",
    "        new_data_dic[key]['labels'][i] += l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process s23\n",
      "process s18\n",
      "process s13\n",
      "process s27\n",
      "process s31\n",
      "process s16\n",
      "process s28\n",
      "process s12\n",
      "process s04\n",
      "process s19\n",
      "process s25\n",
      "process s10\n",
      "process s17\n",
      "process s06\n",
      "process s30\n",
      "process s09\n",
      "process s05\n",
      "process s20\n",
      "process s07\n",
      "process s01\n",
      "process s15\n",
      "process s22\n",
      "process s02\n",
      "process s03\n",
      "process s11\n",
      "process s29\n",
      "process s21\n",
      "process s24\n",
      "process s26\n",
      "process s32\n",
      "process s14\n",
      "process s08\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "train_label = []\n",
    "test_data = []\n",
    "test_label = []\n",
    "for i in new_data_dic:\n",
    "    print(\"process {}\".format(i))\n",
    "    if i != 's02':\n",
    "        \n",
    "        for j in range(len(new_data_dic[i]['labels'])):\n",
    "            temp = np.array(new_data_dic[i]['data'][j]).reshape(-1, 32*101)[0]\n",
    "            train_data.append(temp)\n",
    "            train_label.append(new_data_dic[i]['labels'][j])\n",
    "    else:\n",
    "        for j in range(len(new_data_dic[i]['labels'])):\n",
    "            temp = np.array(new_data_dic[i]['data'][j]).reshape(-1, 32*101)[0]\n",
    "            test_data.append(temp)\n",
    "            test_label.append(new_data_dic[i]['labels'][j])\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=True, random_state=123456, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=123456, criterion='entropy')\n",
    "\n",
    "# fit it to our data\n",
    "dt.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The accuracy of Random Forest was the highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is: 72.5%\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(len(test_data)):\n",
    "    result.append(dt.predict(test_data[i].reshape(1,-1))[0])\n",
    "\n",
    "count = 0\n",
    "for index, i in enumerate(result):\n",
    "    for j in range(len(i)):\n",
    "        if(i[j]==test_label[index][j]):\n",
    "            count += 1\n",
    "print(\"The Accuracy is: {}%\".format(count/(len(test_label)*4) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_data_dic_3 = defaultdict(lambda:defaultdict(lambda:[]))\n",
    "for key in data_dic.keys():\n",
    "    par = int(key[1:])\n",
    "    \n",
    "    for i, vid in enumerate(data_dic[key]['data']):\n",
    "        new_data_dic_3[key]['data'].append([])\n",
    "        for chnn in vid[:-8]:\n",
    "            l =preprocessing(np.array(chnn))\n",
    "            for batch in range(0,10):\n",
    "                l = l+preprocessing(np.array(chnn[batch*807:max((batch+1)*807, 8064)]))\n",
    "            new_data_dic_3[key]['data'][i].append(np.array([par, i+1]+l))\n",
    "    for i,  vid in enumerate(data_dic[key]['labels']):\n",
    "        l2 = []\n",
    "        new_data_dic_3[key]['labels'].append([])\n",
    "        for value in vid:\n",
    "            if value>=6:\n",
    "                l2.append(2)\n",
    "            if value<6 and value >= 4:\n",
    "                l2.append(1)\n",
    "            if value < 4:\n",
    "                l2.append(0)\n",
    "        new_data_dic_3[key]['labels'][i] += l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process s23\n",
      "process s18\n",
      "process s13\n",
      "process s27\n",
      "process s31\n",
      "process s16\n",
      "process s28\n",
      "process s12\n",
      "process s04\n",
      "process s19\n",
      "process s25\n",
      "process s10\n",
      "process s17\n",
      "process s06\n",
      "process s30\n",
      "process s09\n",
      "process s05\n",
      "process s20\n",
      "process s07\n",
      "process s01\n",
      "process s15\n",
      "process s22\n",
      "process s02\n",
      "process s03\n",
      "process s11\n",
      "process s29\n",
      "process s21\n",
      "process s24\n",
      "process s26\n",
      "process s32\n",
      "process s14\n",
      "process s08\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "train_data_3 = []\n",
    "train_label_3 = []\n",
    "test_data_3 = []\n",
    "test_label_3 = []\n",
    "for i in new_data_dic:\n",
    "    print(\"process {}\".format(i))\n",
    "    if i != 's02':\n",
    "        for j in range(len(new_data_dic_3[i]['labels'])):\n",
    "            temp = np.array(new_data_dic_3[i]['data'][j]).reshape(-1, 32*101)[0]\n",
    "            train_data_3.append(temp)\n",
    "            train_label_3.append(new_data_dic_3[i]['labels'][j])\n",
    "    else:\n",
    "        for j in range(len(new_data_dic_3[i]['labels'])):\n",
    "            temp = np.array(new_data_dic_3[i]['data'][j]).reshape(-1, 32*101)[0]\n",
    "            test_data_3.append(temp)\n",
    "            test_label_3.append(new_data_dic_3[i]['labels'][j])\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=True, random_state=123456, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_3 = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=123456, criterion='entropy')\n",
    "\n",
    "# fit it to our data\n",
    "dt_3.fit(train_data_3, train_label_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is: 50.0%\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(len(test_data_3)):\n",
    "#     print(dt_3.predict(test_data_3[i].reshape(1,-1))[0])\n",
    "    result.append(dt_3.predict(test_data_3[i].reshape(1,-1))[0])\n",
    "\n",
    "count = 0\n",
    "for index, i in enumerate(result):\n",
    "    for j in range(len(i)):\n",
    "        if(i[j]==test_label_3[index][j]):\n",
    "            count += 1\n",
    "print(\"The Accuracy is: {}%\".format(count/(len(test_label_3)*4) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "- 2 Classes accuracy 72.5%\n",
    "- 3 Classes accuracy 50%\n",
    "\n",
    "- Best algorithm in this experiment!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
