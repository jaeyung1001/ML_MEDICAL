{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import _pickle as cPickle\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn.init\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirname = './data_preprocessed_python'\n",
    "filenames = os.listdir(dirname)\n",
    "data_dic = defaultdict(lambda:[])\n",
    "for i, filename in enumerate(filenames):\n",
    "    full_filename = os.path.join(dirname, filename)\n",
    "    x = cPickle.load(open(full_filename, 'rb'), encoding='ISO-8859-1')\n",
    "    data_dic[filename[:-4]] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis, skew\n",
    "def preprocessing(data):\n",
    "    result = []\n",
    "    mean = np.mean(data)\n",
    "    median = np.median(data)\n",
    "    maximum = np.amax(data)\n",
    "    minimum = np.amin(data)\n",
    "    std_dev = np.std(data)\n",
    "    var = np.var(data)\n",
    "    ran = np.ptp(data)\n",
    "    skewness = skew(data)\n",
    "    kurto = kurtosis(data)\n",
    "    result=[mean, median, maximum, minimum,\n",
    "                   std_dev, var, ran, skewness, kurto]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make features and reform to use comfortably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_data_dic = defaultdict(lambda:defaultdict(lambda:[]))\n",
    "for key in data_dic.keys():\n",
    "    par = int(key[1:])\n",
    "    for i, vid in enumerate(data_dic[key]['data']):\n",
    "        new_data_dic[key]['data'].append([])\n",
    "        for chnn in vid[:-8]:\n",
    "            l =preprocessing(np.array(chnn))\n",
    "            for batch in range(0,10):\n",
    "                l = l+preprocessing(np.array(chnn[batch*807:max((batch+1)*807, 8064)]))\n",
    "            new_data_dic[key]['data'][i].append(np.array([par, i+1]+l))\n",
    "    for i,  vid in enumerate(data_dic[key]['labels']):\n",
    "        l2 = []\n",
    "        l3 = []\n",
    "        new_data_dic[key]['labels'].append([])\n",
    "        new_data_dic[key]['labels2'].append([])\n",
    "        for value in vid:\n",
    "            if value>=5:\n",
    "                l2.append(1)\n",
    "                l2.append(0)\n",
    "            else:\n",
    "                l2.append(0)\n",
    "                l2.append(1)\n",
    "            if value>=6:\n",
    "                l3.append(1)\n",
    "                l3.append(0)\n",
    "                l3.append(0)\n",
    "            elif value>=4 and value<6:\n",
    "                l3.append(0)\n",
    "                l3.append(1)\n",
    "                l3.append(0)\n",
    "            else:\n",
    "                l3.append(0)\n",
    "                l3.append(0)\n",
    "                l3.append(1)\n",
    "        new_data_dic[key]['labels'][i] += l2\n",
    "        new_data_dic[key]['labels2'][i] += l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "1240\n",
      "(array([[  1.00000000e+00,   2.00000000e+00,  -8.27121269e-02, ...,\n",
      "          3.70042683e+01,  -5.08154218e-02,   8.69235014e-01],\n",
      "       [  1.00000000e+00,   2.00000000e+00,  -3.13505384e-02, ...,\n",
      "          4.18200988e+01,   1.11964916e-01,   1.39442973e+00],\n",
      "       [  1.00000000e+00,   2.00000000e+00,  -2.04664705e-02, ...,\n",
      "          3.87172925e+01,   5.88444745e-02,   9.21659624e-01],\n",
      "       ..., \n",
      "       [  1.00000000e+00,   2.00000000e+00,   6.82457494e-02, ...,\n",
      "          2.08783110e+01,   1.04035679e-01,   1.35067118e-03],\n",
      "       [  1.00000000e+00,   2.00000000e+00,   1.42352938e-01, ...,\n",
      "          5.25603937e+01,   1.71642208e-01,   2.84520300e+00],\n",
      "       [  1.00000000e+00,   2.00000000e+00,   1.56159050e-01, ...,\n",
      "          3.58672933e+01,   3.79596399e-01,   9.76703888e-01]]), [1, 0, 1, 0, 1, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "data_loader = []\n",
    "test_loader = []\n",
    "idx = 0\n",
    "print(len(new_data_dic.keys()))\n",
    "for par in new_data_dic.keys():\n",
    "    if par != 's02':\n",
    "        for i, vid in enumerate(new_data_dic[par]['data']):\n",
    "            data_loader.append((np.array(vid), new_data_dic[par]['labels'][i]))\n",
    "            idx +=1\n",
    "    else:\n",
    "        for i, vid in enumerate(new_data_dic[par]['data']):\n",
    "            test_loader.append((np.array(vid), new_data_dic[par]['labels'][i]))\n",
    "            idx +=1\n",
    "print(len(data_loader))\n",
    "print(data_loader[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "1240\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "data_loader2 = []\n",
    "test_loader2 = []\n",
    "trX = []\n",
    "trY = []\n",
    "teX = []\n",
    "teY = []\n",
    "idx = 0\n",
    "print(len(new_data_dic.keys()))\n",
    "for par in new_data_dic.keys():\n",
    "    if par != 's02':\n",
    "        for i, vid in enumerate(new_data_dic[par]['data']):\n",
    "            data_loader2.append((np.array(vid), new_data_dic[par]['labels2'][i]))\n",
    "            idx +=1\n",
    "    else:\n",
    "        for i, vid in enumerate(new_data_dic[par]['data']):\n",
    "            test_loader2.append((np.array(vid), new_data_dic[par]['labels2'][i]))\n",
    "            idx +=1\n",
    "print(len(data_loader2))\n",
    "for i in data_loader:\n",
    "    trX.append(i[0])\n",
    "    trY.append(i[1][:2])\n",
    "for i in test_loader:\n",
    "    teX.append(i[0])\n",
    "    teY.append(i[1][:2])\n",
    "print(len(teY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, test - arousal 2 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, training error: 1026646.1875, training accuracy: 0.4113\n",
      "Testing Accuracy: 0.4000\n",
      "Epoch: 1, training error: 99390.5938, training accuracy: 0.4113\n",
      "Testing Accuracy: 0.4000\n",
      "Epoch: 2, training error: 3862.2773, training accuracy: 0.4484\n",
      "Testing Accuracy: 0.4000\n",
      "Epoch: 3, training error: 50157.6055, training accuracy: 0.5887\n",
      "Testing Accuracy: 0.6000\n",
      "Epoch: 4, training error: 7296.2231, training accuracy: 0.4137\n",
      "Testing Accuracy: 0.4000\n",
      "Epoch: 5, training error: 23503.0293, training accuracy: 0.5887\n",
      "Testing Accuracy: 0.6000\n",
      "Epoch: 6, training error: 2944.3008, training accuracy: 0.5081\n",
      "Testing Accuracy: 0.4000\n",
      "Epoch: 7, training error: 19463.2578, training accuracy: 0.5887\n",
      "Testing Accuracy: 0.6000\n",
      "Epoch: 8, training error: 2847.5857, training accuracy: 0.5161\n",
      "Testing Accuracy: 0.4000\n",
      "Epoch: 9, training error: 15236.6094, training accuracy: 0.5887\n",
      "Testing Accuracy: 0.6000\n",
      "Epoch: 10, training error: 2474.8794, training accuracy: 0.5685\n",
      "Testing Accuracy: 0.4250\n",
      "Epoch: 11, training error: 9643.3789, training accuracy: 0.5887\n",
      "Testing Accuracy: 0.6000\n",
      "Epoch: 12, training error: 2048.9863, training accuracy: 0.5855\n",
      "Testing Accuracy: 0.5000\n",
      "Epoch: 13, training error: 9824.1758, training accuracy: 0.5887\n",
      "Testing Accuracy: 0.6000\n",
      "Epoch: 14, training error: 1755.7308, training accuracy: 0.5702\n",
      "Testing Accuracy: 0.5000\n",
      "Epoch: 15, training error: 9148.0449, training accuracy: 0.5887\n",
      "Testing Accuracy: 0.6000\n",
      "Epoch: 16, training error: 1770.6903, training accuracy: 0.5677\n",
      "Testing Accuracy: 0.4000\n",
      "Epoch: 17, training error: 8148.2363, training accuracy: 0.5887\n",
      "Testing Accuracy: 0.6000\n",
      "Epoch: 18, training error: 1499.1141, training accuracy: 0.5935\n",
      "Testing Accuracy: 0.6000\n",
      "Epoch: 19, training error: 6682.9004, training accuracy: 0.5887\n",
      "Testing Accuracy: 0.6000\n",
      "time elapsed: 4389.31s\n"
     ]
    }
   ],
   "source": [
    "trX = []\n",
    "trY = []\n",
    "teX = []\n",
    "teY = []\n",
    "for i in data_loader:\n",
    "    trX.append(i[0])\n",
    "    trY.append(i[1][2:4])\n",
    "for i in test_loader:\n",
    "    teX.append(i[0])\n",
    "    teY.append(i[1][2:4])\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 32, 101, 1])\n",
    "\n",
    "Y = tf.placeholder(\"float\", [None, 2])\n",
    "\n",
    "trX = torch.Tensor(np.array(trX).reshape(-1, 32, 101, 1))\n",
    "trY = np.array(trY)\n",
    "\n",
    "training_epochs = 20\n",
    "\n",
    "w = init_weights([101, 32, 1, 32])       # 101x32x1 conv, 32 outputs\n",
    "w2 = init_weights([3, 3, 32, 64])     # 3x3x32 conv, 64 outputs\n",
    "w3 = init_weights([3, 3, 64, 128])    # 3x3x32 conv, 128 outputs\n",
    "w4 = init_weights([6656, 625]) # FC 6656 inputs, 625 outputs\n",
    "w_o = init_weights([625, 2])         # FC 625 inputs, 2 outputs (labels)\n",
    "\n",
    "p_keep_conv = tf.placeholder(tf.float32)\n",
    "p_keep_hidden = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "py_x = model(trX, w, w2, w3, w4, w_o, p_keep_conv, p_keep_hidden)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=py_x, labels=trY))\n",
    "train_op = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n",
    "predict_op = tf.argmax(py_x, 1)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # you need to initialize all variables\n",
    "    start_time = time.time()\n",
    "    sess.run(init)\n",
    "\n",
    "    for i in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        avg_training_accuracy = 0.\n",
    "        \n",
    "        #not using batch\n",
    "        batch_xs = trX\n",
    "        batch_ys = trY\n",
    "\n",
    "        batch_xs_image = torch.Tensor(np.array(batch_xs).reshape(-1, 32, 101, 1))\n",
    "        batch_ys_image = np.array(batch_ys)\n",
    "\n",
    "        sess.run(train_op, feed_dict={X: batch_xs_image, Y: batch_ys_image,\n",
    "                                      p_keep_conv: 0.8, p_keep_hidden: 0.5})\n",
    "        # Training average cost\n",
    "        avg_cost += sess.run(cost, feed_dict={X: batch_xs_image, Y: batch_ys, p_keep_conv:1.0, p_keep_hidden:1.0})\n",
    "        avg_training_accuracy += (np.mean(np.argmax(batch_ys, axis=1) ==\n",
    "                     sess.run(predict_op, feed_dict={X: batch_xs_image,\n",
    "                                                    Y: batch_ys_image,\n",
    "                                                    p_keep_conv: 1.0,\n",
    "                                                    p_keep_hidden: 1.0})))\n",
    "            \n",
    "        print(\"Epoch: %d, training error: %.4f, training accuracy: %.4f\"%(i,avg_cost,avg_training_accuracy))\n",
    "\n",
    "        # testing accuracy\n",
    "        teX = torch.Tensor(np.array(teX).reshape(-1, 32, 101, 1))\n",
    "        teY = np.array(teY)\n",
    "        outputs = sess.run(predict_op, feed_dict={X: teX,\n",
    "                                                        Y: teY,\n",
    "                                                        p_keep_conv: 1.0,\n",
    "                                                        p_keep_hidden: 1.0})\n",
    "\n",
    "        cnt = 0\n",
    "        for idx, out in enumerate(outputs[:40]):\n",
    "            if teY[idx][out] == 1:\n",
    "                cnt+=1\n",
    "                \n",
    "#         testing_accuracy = np.mean(np.argmax(teY, axis=1) ==\n",
    "#                          sess.run(predict_op, feed_dict={X: teX,\n",
    "#                                                         Y: teY,\n",
    "#                                                         p_keep_conv: 1.0,\n",
    "#                                                         p_keep_hidden: 1.0}))\n",
    "        print(\"Testing Accuracy: %.4f\"%(cnt/40))\n",
    "        \n",
    "        if testing_accuracy == 1.0:\n",
    "            print(\"Early stop\")\n",
    "            break\n",
    "        \n",
    "    print(\"time elapsed: {:.2f}s\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, test - arousal 3 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, training error: 715273.6250, training accuracy: 0.2863\n",
      "Testing Accuracy: 0.3250\n",
      "Epoch: 1, training error: 186929.0312, training accuracy: 0.4121\n",
      "Testing Accuracy: 0.5250\n",
      "Epoch: 2, training error: 36115.8242, training accuracy: 0.3815\n",
      "Testing Accuracy: 0.3500\n",
      "Epoch: 3, training error: 30610.7676, training accuracy: 0.2863\n",
      "Testing Accuracy: 0.3250\n",
      "Epoch: 4, training error: 15073.0020, training accuracy: 0.4121\n",
      "Testing Accuracy: 0.5250\n",
      "Epoch: 5, training error: 12053.9277, training accuracy: 0.2887\n",
      "Testing Accuracy: 0.3250\n",
      "Epoch: 6, training error: 10629.0625, training accuracy: 0.3363\n",
      "Testing Accuracy: 0.1750\n",
      "Epoch: 7, training error: 2975.2471, training accuracy: 0.3597\n",
      "Testing Accuracy: 0.4000\n",
      "Epoch: 8, training error: 8648.0723, training accuracy: 0.3121\n",
      "Testing Accuracy: 0.1500\n",
      "Epoch: 9, training error: 3031.4395, training accuracy: 0.4339\n",
      "Testing Accuracy: 0.5250\n",
      "Epoch: 10, training error: 5594.1826, training accuracy: 0.3073\n",
      "Testing Accuracy: 0.1500\n",
      "Epoch: 11, training error: 1705.2358, training accuracy: 0.4169\n",
      "Testing Accuracy: 0.4250\n",
      "Epoch: 12, training error: 5631.0269, training accuracy: 0.3032\n",
      "Testing Accuracy: 0.1500\n",
      "Epoch: 13, training error: 1647.9130, training accuracy: 0.4290\n",
      "Testing Accuracy: 0.4000\n",
      "Epoch: 14, training error: 3831.1919, training accuracy: 0.3161\n",
      "Testing Accuracy: 0.1500\n",
      "Epoch: 15, training error: 1300.1324, training accuracy: 0.4145\n",
      "Testing Accuracy: 0.4000\n",
      "Epoch: 16, training error: 4540.2603, training accuracy: 0.3129\n",
      "Testing Accuracy: 0.1500\n",
      "Epoch: 17, training error: 1158.4200, training accuracy: 0.4024\n",
      "Testing Accuracy: 0.3750\n",
      "Epoch: 18, training error: 3576.2500, training accuracy: 0.3105\n",
      "Testing Accuracy: 0.1750\n",
      "Epoch: 19, training error: 1150.5333, training accuracy: 0.4008\n",
      "Testing Accuracy: 0.5250\n",
      "time elapsed: 4439.41s\n"
     ]
    }
   ],
   "source": [
    "trX = []\n",
    "trY = []\n",
    "teX = []\n",
    "teY = []\n",
    "for i in data_loader2:\n",
    "    trX.append(i[0])\n",
    "    trY.append(i[1][3:6])\n",
    "for i in test_loader2:\n",
    "    teX.append(i[0])\n",
    "    teY.append(i[1][3:6])\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 32, 101, 1])\n",
    "\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "\n",
    "trX = torch.Tensor(np.array(trX).reshape(-1, 32, 101, 1))\n",
    "trY = np.array(trY)\n",
    "    \n",
    "w = init_weights([101, 32, 1, 32])       # 101x32x1 conv, 32 outputs\n",
    "w2 = init_weights([3, 3, 32, 64])     # 3x3x32 conv, 64 outputs\n",
    "w3 = init_weights([3, 3, 64, 128])    # 3x3x32 conv, 128 outputs\n",
    "w4 = init_weights([6656, 625]) # FC 6656 inputs, 625 outputs\n",
    "w_o = init_weights([625, 3])         # FC 625 inputs, 2 outputs (labels)\n",
    "\n",
    "p_keep_conv = tf.placeholder(tf.float32)\n",
    "p_keep_hidden = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "py_x = model(trX, w, w2, w3, w4, w_o, p_keep_conv, p_keep_hidden)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=py_x, labels=trY))\n",
    "train_op = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n",
    "predict_op = tf.argmax(py_x, 1)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # you need to initialize all variables\n",
    "    start_time = time.time()\n",
    "    sess.run(init)\n",
    "\n",
    "    for i in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        avg_training_accuracy = 0.\n",
    "        \n",
    "        #not using batch\n",
    "        batch_xs = trX\n",
    "        batch_ys = trY\n",
    "\n",
    "        batch_xs_image = torch.Tensor(np.array(batch_xs).reshape(-1, 32, 101, 1))\n",
    "        batch_ys_image = np.array(batch_ys)\n",
    "\n",
    "        sess.run(train_op, feed_dict={X: batch_xs_image, Y: batch_ys_image,\n",
    "                                      p_keep_conv: 0.8, p_keep_hidden: 0.5})\n",
    "        # Training average cost\n",
    "        avg_cost += sess.run(cost, feed_dict={X: batch_xs_image, Y: batch_ys, p_keep_conv:1.0, p_keep_hidden:1.0})\n",
    "        avg_training_accuracy += (np.mean(np.argmax(batch_ys, axis=1) ==\n",
    "                     sess.run(predict_op, feed_dict={X: batch_xs_image,\n",
    "                                                    Y: batch_ys_image,\n",
    "                                                    p_keep_conv: 1.0,\n",
    "                                                    p_keep_hidden: 1.0})))\n",
    "            \n",
    "        print(\"Epoch: %d, training error: %.4f, training accuracy: %.4f\"%(i,avg_cost,avg_training_accuracy))\n",
    "\n",
    "        # testing accuracy\n",
    "        teX = torch.Tensor(np.array(teX).reshape(-1, 32, 101, 1))\n",
    "        teY = np.array(teY)\n",
    "        outputs = sess.run(predict_op, feed_dict={X: teX,\n",
    "                                                        Y: teY,\n",
    "                                                        p_keep_conv: 1.0,\n",
    "                                                        p_keep_hidden: 1.0})\n",
    "\n",
    "        cnt = 0\n",
    "        for idx, out in enumerate(outputs[:40]):\n",
    "            if teY[idx][out] == 1:\n",
    "                cnt+=1\n",
    "                \n",
    "#         testing_accuracy = np.mean(np.argmax(teY, axis=1) ==\n",
    "#                          sess.run(predict_op, feed_dict={X: teX,\n",
    "#                                                         Y: teY,\n",
    "#                                                         p_keep_conv: 1.0,\n",
    "#                                                         p_keep_hidden: 1.0}))\n",
    "        print(\"Testing Accuracy: %.4f\"%(cnt/40))\n",
    "        \n",
    "        if testing_accuracy == 1.0:\n",
    "            print(\"Early stop\")\n",
    "            break\n",
    "        \n",
    "    print(\"time elapsed: {:.2f}s\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I don't know why all the predicted labels are the same....\n",
    "We tried several methods using smaller training set(size - 40) but we cannot fix it.\n",
    "#### So we use another library(PyTorch) and other algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, test - valence 2 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "Epoch: 0, training error: 1734375.6250, training accuracy: 0.5250\n",
      "Testing Accuracy: 0.3750\n",
      "Epoch: 1, training error: 32420.9785, training accuracy: 0.4750\n",
      "Testing Accuracy: 0.6250\n",
      "Epoch: 2, training error: 11913.7402, training accuracy: 0.5250\n",
      "Testing Accuracy: 0.3750\n",
      "Epoch: 3, training error: 2246.6777, training accuracy: 0.4750\n",
      "Testing Accuracy: 0.6250\n",
      "Epoch: 4, training error: 9822.4473, training accuracy: 0.5250\n",
      "Testing Accuracy: 0.3750\n",
      "time elapsed: 510.71s\n"
     ]
    }
   ],
   "source": [
    "trX = []\n",
    "trY = []\n",
    "teX = []\n",
    "teY = []\n",
    "training_epochs = 20\n",
    "for i in data_loader:\n",
    "    trX.append(i[0])\n",
    "    trY.append(i[1][:2])\n",
    "for i in test_loader:\n",
    "    teX.append(i[0])\n",
    "    teY.append(i[1][:2])\n",
    "print(len(teY))\n",
    "\n",
    "# Read data\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 32, 101, 1])\n",
    "\n",
    "Y = tf.placeholder(\"float\", [None, 2])\n",
    "\n",
    "trX = torch.Tensor(np.array(trX[:40]).reshape(-1, 32, 101, 1))\n",
    "trY = np.array(trY[:40])\n",
    "\n",
    "w = init_weights([101, 32, 1, 32])       # 101x32x1 conv, 32 outputs\n",
    "w2 = init_weights([101, 32, 32, 64])     # 3x3x32 conv, 64 outputs\n",
    "w3 = init_weights([101, 32, 64, 128])    # 3x3x32 conv, 128 outputs\n",
    "w4 = init_weights([6656, 625]) # FC 6656 inputs, 625 outputs\n",
    "w_o = init_weights([625, 2])         # FC 625 inputs, 2 outputs (labels)\n",
    "\n",
    "p_keep_conv = tf.placeholder(tf.float32)\n",
    "p_keep_hidden = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "py_x = model(trX, w, w2, w3, w4, w_o, p_keep_conv, p_keep_hidden)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=py_x, labels=trY))\n",
    "train_op = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n",
    "predict_op = tf.argmax(py_x, 1)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # you need to initialize all variables\n",
    "    start_time = time.time()\n",
    "    sess.run(init)\n",
    "\n",
    "    for i in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        avg_training_accuracy = 0.\n",
    "        \n",
    "        #not using batch\n",
    "        batch_xs = trX\n",
    "        batch_ys = trY\n",
    "\n",
    "        batch_xs_image = torch.Tensor(np.array(batch_xs).reshape(-1, 32, 101, 1))\n",
    "        batch_ys_image = np.array(batch_ys)\n",
    "\n",
    "        sess.run(train_op, feed_dict={X: batch_xs_image, Y: batch_ys_image,\n",
    "                                      p_keep_conv: 0.8, p_keep_hidden: 0.5})\n",
    "        # Training average cost\n",
    "        avg_cost += sess.run(cost, feed_dict={X: batch_xs_image, Y: batch_ys, p_keep_conv:1.0, p_keep_hidden:1.0})\n",
    "        avg_training_accuracy += (np.mean(np.argmax(batch_ys, axis=1) ==\n",
    "                     sess.run(predict_op, feed_dict={X: batch_xs_image,\n",
    "                                                    Y: batch_ys_image,\n",
    "                                                    p_keep_conv: 1.0,\n",
    "                                                    p_keep_hidden: 1.0})))\n",
    "            \n",
    "        print(\"Epoch: %d, training error: %.4f, training accuracy: %.4f\"%(i,avg_cost,avg_training_accuracy))\n",
    "\n",
    "        # testing accuracy\n",
    "        teX = torch.Tensor(np.array(teX).reshape(-1, 32, 101, 1))\n",
    "        teY = np.array(teY)\n",
    "\n",
    "        testing_accuracy = np.mean(np.argmax(teY, axis=1) ==\n",
    "                         sess.run(predict_op, feed_dict={X: teX,\n",
    "                                                        Y: teY,\n",
    "                                                        p_keep_conv: 1.0,\n",
    "                                                        p_keep_hidden: 1.0}))\n",
    "        print(\"Testing Accuracy: %.4f\"%(testing_accuracy))\n",
    "        \n",
    "        if testing_accuracy == 1.0:\n",
    "            print(\"Early stop\")\n",
    "            break\n",
    "        \n",
    "    print(\"time elapsed: {:.2f}s\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
