{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import _pickle as cPickle\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.stats import kurtosis, skew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    result = []\n",
    "    mean = np.mean(data)\n",
    "    median = np.median(data)\n",
    "    maximum = np.amax(data)\n",
    "    minimum = np.amin(data)\n",
    "    std_dev = np.std(data)\n",
    "    var = np.var(data)\n",
    "    ran = np.ptp(data)\n",
    "    skewness = skew(data)\n",
    "    kurto = kurtosis(data)\n",
    "    result=[mean, median, maximum, minimum,\n",
    "                   std_dev, var, ran, skewness, kurto]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirname = './data_preprocessed_python'\n",
    "filenames = os.listdir(dirname)\n",
    "data_dic = defaultdict(lambda:[])\n",
    "for i, filename in enumerate(filenames):\n",
    "    full_filename = os.path.join(dirname, filename)\n",
    "    x = cPickle.load(open(full_filename, 'rb'), encoding='ISO-8859-1')\n",
    "    data_dic[filename[:-4]] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_data_dic = defaultdict(lambda:defaultdict(lambda:[]))\n",
    "for key in data_dic.keys():\n",
    "    par = int(key[1:])\n",
    "    \n",
    "    for i, vid in enumerate(data_dic[key]['data']):\n",
    "        new_data_dic[key]['data'].append([])\n",
    "        for chnn in vid[:-8]:\n",
    "            l =preprocessing(np.array(chnn))\n",
    "            for batch in range(0,10):\n",
    "                l = l+preprocessing(np.array(chnn[batch*807:max((batch+1)*807, 8064)]))\n",
    "            new_data_dic[key]['data'][i].append(np.array([par, i+1]+l))\n",
    "    for i,  vid in enumerate(data_dic[key]['labels']):\n",
    "        l2 = []\n",
    "        new_data_dic[key]['labels'].append([])\n",
    "        for value in vid:\n",
    "            l2.append(value)\n",
    "        new_data_dic[key]['labels'][i] += l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "data_loader = []\n",
    "idx = 0\n",
    "print(len(new_data_dic.keys()))\n",
    "for par in new_data_dic.keys():\n",
    "    if par != 's02':\n",
    "        for i, vid in enumerate(new_data_dic[par]['data']):\n",
    "            data_loader.append((np.array(vid), new_data_dic[par]['labels'][i]))\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set train & test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process s01\n",
      "process s02\n",
      "process s03\n",
      "process s04\n",
      "process s05\n",
      "process s06\n",
      "process s07\n",
      "process s08\n",
      "process s09\n",
      "process s10\n",
      "process s11\n",
      "process s12\n",
      "process s13\n",
      "process s14\n",
      "process s15\n",
      "process s16\n",
      "process s17\n",
      "process s18\n",
      "process s19\n",
      "process s20\n",
      "process s21\n",
      "process s22\n",
      "process s23\n",
      "process s24\n",
      "process s25\n",
      "process s26\n",
      "process s27\n",
      "process s28\n",
      "process s29\n",
      "process s30\n",
      "process s31\n",
      "process s32\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "train_label = []\n",
    "test_data = []\n",
    "test_label = []\n",
    "for i in new_data_dic:\n",
    "    print(\"process {}\".format(i))\n",
    "    if i != 's02':\n",
    "        \n",
    "        for j in range(len(new_data_dic[i]['labels'])):\n",
    "            temp = np.array(new_data_dic[i]['data'][j]).reshape(-1, 32*101)[0]\n",
    "            train_data.append(temp)\n",
    "            train_label.append(new_data_dic[i]['labels'][j])\n",
    "    else:\n",
    "        for j in range(len(new_data_dic[i]['labels'])):\n",
    "            temp = np.array(new_data_dic[i]['data'][j]).reshape(-1, 32*101)[0]\n",
    "            test_data.append(temp)\n",
    "            test_label.append(new_data_dic[i]['labels'][j])\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define DNN model\n",
    "- nodes : 3232 -> 5000 -> 500 -> 1000 -> 4\n",
    "- activate function : ReLU\n",
    "- Dropout probability : 0.25(input), 0.5(hidden layer)\n",
    "- Loss function : MSELoss()\n",
    "- optimizer : RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3232, out_features=5000, bias=True)\n",
      "  (1): Dropout(p=0.25)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=5000, out_features=500, bias=True)\n",
      "  (4): Dropout(p=0.5)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=500, out_features=1000, bias=True)\n",
      "  (7): Dropout(p=0.5)\n",
      "  (8): ReLU()\n",
      "  (9): Linear(in_features=1000, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "linear1 = torch.nn.Linear(3232, 5000, bias=True)\n",
    "linear2 = torch.nn.Linear(5000, 500, bias=True)\n",
    "linear3 = torch.nn.Linear(500, 1000, bias=True)\n",
    "linear4 = torch.nn.Linear(1000, 4, bias=True)\n",
    "relu = torch.nn.ReLU()\n",
    "model_1 = torch.nn.Sequential(linear1, torch.nn.Dropout(0.25), relu, \n",
    "                           linear2, torch.nn.Dropout(0.5), relu,\n",
    "                           linear3, torch.nn.Dropout(0.5), relu,\n",
    "                           linear4)\n",
    "print(model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### let's train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1] cost = 59268.625\n",
      "[Epoch:    2] cost = 18937.832\n",
      "[Epoch:    3] cost = 12786.5693\n",
      "[Epoch:    4] cost = 10477.3994\n",
      "[Epoch:    5] cost = 9731.93066\n",
      "[Epoch:    6] cost = 10046.6348\n",
      "[Epoch:    7] cost = 7328.01367\n",
      "[Epoch:    8] cost = 9021.86133\n",
      "[Epoch:    9] cost = 11640.5078\n",
      "[Epoch:   10] cost = 9779.1377\n",
      "[Epoch:   11] cost = 7328.354\n",
      "[Epoch:   12] cost = 7731.64453\n",
      "[Epoch:   13] cost = 7987.19287\n",
      "[Epoch:   14] cost = 9754.41895\n",
      "[Epoch:   15] cost = 7438.60889\n",
      "[Epoch:   16] cost = 7943.44482\n",
      "[Epoch:   17] cost = 8137.98682\n",
      "[Epoch:   18] cost = 7677.93213\n",
      "[Epoch:   19] cost = 8466.42676\n",
      "[Epoch:   20] cost = 8196.48242\n",
      "[Epoch:   21] cost = 10652.7861\n",
      "[Epoch:   22] cost = 10716.8955\n",
      "[Epoch:   23] cost = 8147.56836\n",
      "[Epoch:   24] cost = 10065.4395\n",
      "[Epoch:   25] cost = 6176.28223\n",
      "[Epoch:   26] cost = 7714.74072\n",
      "[Epoch:   27] cost = 9396.22754\n",
      "[Epoch:   28] cost = 7256.9209\n",
      "[Epoch:   29] cost = 9431.3418\n",
      "[Epoch:   30] cost = 7411.97412\n",
      "[Epoch:   31] cost = 7138.22461\n",
      "[Epoch:   32] cost = 7150.59814\n",
      "[Epoch:   33] cost = 7088.04785\n",
      "[Epoch:   34] cost = 6700.12988\n",
      "[Epoch:   35] cost = 6408.20654\n",
      "[Epoch:   36] cost = 6566.77197\n",
      "[Epoch:   37] cost = 8410.66797\n",
      "[Epoch:   38] cost = 7561.81494\n",
      "[Epoch:   39] cost = 6747.60547\n",
      "[Epoch:   40] cost = 7847.00244\n",
      "[Epoch:   41] cost = 7448.18555\n",
      "[Epoch:   42] cost = 5943.96777\n",
      "[Epoch:   43] cost = 8213.87305\n",
      "[Epoch:   44] cost = 5659.02197\n",
      "[Epoch:   45] cost = 6967.49268\n",
      "[Epoch:   46] cost = 6304.90479\n",
      "[Epoch:   47] cost = 10110.2246\n",
      "[Epoch:   48] cost = 5844.82715\n",
      "[Epoch:   49] cost = 5825.86621\n",
      "[Epoch:   50] cost = 5733.67725\n",
      "[Epoch:   51] cost = 11872.2666\n",
      "[Epoch:   52] cost = 8632.37012\n",
      "[Epoch:   53] cost = 6111.81738\n",
      "[Epoch:   54] cost = 5651.92236\n",
      "[Epoch:   55] cost = 6770.9043\n",
      "[Epoch:   56] cost = 6117.96289\n",
      "[Epoch:   57] cost = 6783.60498\n",
      "[Epoch:   58] cost = 5068.08496\n",
      "[Epoch:   59] cost = 5282.16748\n",
      "[Epoch:   60] cost = 5292.51074\n",
      "[Epoch:   61] cost = 5479.20117\n",
      "[Epoch:   62] cost = 5402.6167\n",
      "[Epoch:   63] cost = 4728.61572\n",
      "[Epoch:   64] cost = 5147.49268\n",
      "[Epoch:   65] cost = 4639.69629\n",
      "[Epoch:   66] cost = 8620.90137\n",
      "[Epoch:   67] cost = 5382.22803\n",
      "[Epoch:   68] cost = 5480.16992\n",
      "[Epoch:   69] cost = 5744.30518\n",
      "[Epoch:   70] cost = 5208.97607\n",
      "[Epoch:   71] cost = 5563.36475\n",
      "[Epoch:   72] cost = 4727.56348\n",
      "[Epoch:   73] cost = 5259.55518\n",
      "[Epoch:   74] cost = 4742.65918\n",
      "[Epoch:   75] cost = 4673.04297\n",
      "[Epoch:   76] cost = 4640.2417\n",
      "[Epoch:   77] cost = 6658.91797\n",
      "[Epoch:   78] cost = 4472.38428\n",
      "[Epoch:   79] cost = 4338.44629\n",
      "[Epoch:   80] cost = 5606.20068\n",
      "[Epoch:   81] cost = 4314.02393\n",
      "[Epoch:   82] cost = 4568.58008\n",
      "[Epoch:   83] cost = 4441.01367\n",
      "[Epoch:   84] cost = 5414.729\n",
      "[Epoch:   85] cost = 4966.21875\n",
      "[Epoch:   86] cost = 4366.75195\n",
      "[Epoch:   87] cost = 5316.56299\n",
      "[Epoch:   88] cost = 4143.63525\n",
      "[Epoch:   89] cost = 4732.49902\n",
      "[Epoch:   90] cost = 5276.43652\n",
      "[Epoch:   91] cost = 4900.54248\n",
      "[Epoch:   92] cost = 4221.08154\n",
      "[Epoch:   93] cost = 4142.21484\n",
      "[Epoch:   94] cost = 3933.6814\n",
      "[Epoch:   95] cost = 3850.41968\n",
      "[Epoch:   96] cost = 4112.86182\n",
      "[Epoch:   97] cost = 3591.61963\n",
      "[Epoch:   98] cost = 4016.90405\n",
      "[Epoch:   99] cost = 3692.8396\n",
      "[Epoch:  100] cost = 4394.42041\n",
      "[Epoch:  101] cost = 3955.44995\n",
      "[Epoch:  102] cost = 4250.95459\n",
      "[Epoch:  103] cost = 4439.8623\n",
      "[Epoch:  104] cost = 3578.14038\n",
      "[Epoch:  105] cost = 4817.11523\n",
      "[Epoch:  106] cost = 3802.8457\n",
      "[Epoch:  107] cost = 3926.33838\n",
      "[Epoch:  108] cost = 3730.31665\n",
      "[Epoch:  109] cost = 3923.75977\n",
      "[Epoch:  110] cost = 3816.85767\n",
      "[Epoch:  111] cost = 4608.4209\n",
      "[Epoch:  112] cost = 3311.76904\n",
      "[Epoch:  113] cost = 3407.29395\n",
      "[Epoch:  114] cost = 3177.39673\n",
      "[Epoch:  115] cost = 3990.77686\n",
      "[Epoch:  116] cost = 3387.94751\n",
      "[Epoch:  117] cost = 3278.59912\n",
      "[Epoch:  118] cost = 3949.86646\n",
      "[Epoch:  119] cost = 3317.11157\n",
      "[Epoch:  120] cost = 3540.60669\n",
      "[Epoch:  121] cost = 3582.43042\n",
      "[Epoch:  122] cost = 4355.229\n",
      "[Epoch:  123] cost = 3194.7915\n",
      "[Epoch:  124] cost = 2966.10693\n",
      "[Epoch:  125] cost = 2859.89209\n",
      "[Epoch:  126] cost = 3171.63574\n",
      "[Epoch:  127] cost = 3368.26562\n",
      "[Epoch:  128] cost = 2901.70752\n",
      "[Epoch:  129] cost = 2895.06152\n",
      "[Epoch:  130] cost = 3062.93481\n",
      "[Epoch:  131] cost = 2831.17041\n",
      "[Epoch:  132] cost = 3041.98364\n",
      "[Epoch:  133] cost = 3150.92725\n",
      "[Epoch:  134] cost = 2806.77075\n",
      "[Epoch:  135] cost = 3407.17749\n",
      "[Epoch:  136] cost = 3206.17798\n",
      "[Epoch:  137] cost = 2819.93018\n",
      "[Epoch:  138] cost = 2793.55591\n",
      "[Epoch:  139] cost = 2838.28638\n",
      "[Epoch:  140] cost = 3832.92212\n",
      "[Epoch:  141] cost = 2603.55151\n",
      "[Epoch:  142] cost = 3359.75049\n",
      "[Epoch:  143] cost = 2622.98047\n",
      "[Epoch:  144] cost = 3297.41772\n",
      "[Epoch:  145] cost = 3316.4187\n",
      "[Epoch:  146] cost = 2510.88232\n",
      "[Epoch:  147] cost = 3121.10791\n",
      "[Epoch:  148] cost = 2533.04077\n",
      "[Epoch:  149] cost = 2393.18262\n",
      "[Epoch:  150] cost = 2740.01611\n",
      "[Epoch:  151] cost = 2756.30469\n",
      "[Epoch:  152] cost = 2680.13599\n",
      "[Epoch:  153] cost = 2620.99731\n",
      "[Epoch:  154] cost = 3083.43359\n",
      "[Epoch:  155] cost = 3274.45605\n",
      "[Epoch:  156] cost = 2436.63818\n",
      "[Epoch:  157] cost = 2433.32471\n",
      "[Epoch:  158] cost = 2561.60571\n",
      "[Epoch:  159] cost = 2251.37378\n",
      "[Epoch:  160] cost = 3683.20752\n",
      "[Epoch:  161] cost = 2297.63501\n",
      "[Epoch:  162] cost = 2543.44604\n",
      "[Epoch:  163] cost = 2227.65601\n",
      "[Epoch:  164] cost = 2094.08838\n",
      "[Epoch:  165] cost = 2609.65308\n",
      "[Epoch:  166] cost = 2482.48047\n",
      "[Epoch:  167] cost = 2184.50488\n",
      "[Epoch:  168] cost = 2392.06226\n",
      "[Epoch:  169] cost = 2088.5896\n",
      "[Epoch:  170] cost = 2344.74072\n",
      "[Epoch:  171] cost = 2048.46533\n",
      "[Epoch:  172] cost = 2143.86987\n",
      "[Epoch:  173] cost = 1943.99915\n",
      "[Epoch:  174] cost = 1963.26355\n",
      "[Epoch:  175] cost = 2232.14624\n",
      "[Epoch:  176] cost = 2182.74414\n",
      "[Epoch:  177] cost = 2098.61792\n",
      "[Epoch:  178] cost = 2192.24683\n",
      "[Epoch:  179] cost = 1996.32666\n",
      "[Epoch:  180] cost = 2050.86548\n",
      "[Epoch:  181] cost = 1944.19873\n",
      "[Epoch:  182] cost = 2111.04321\n",
      "[Epoch:  183] cost = 2132.75586\n",
      "[Epoch:  184] cost = 1839.79883\n",
      "[Epoch:  185] cost = 1893.31921\n",
      "[Epoch:  186] cost = 2042.4563\n",
      "[Epoch:  187] cost = 1766.01953\n",
      "[Epoch:  188] cost = 1795.32654\n",
      "[Epoch:  189] cost = 2159.43628\n",
      "[Epoch:  190] cost = 1901.77856\n",
      "[Epoch:  191] cost = 1850.58069\n",
      "[Epoch:  192] cost = 1700.22327\n",
      "[Epoch:  193] cost = 1928.021\n",
      "[Epoch:  194] cost = 1946.58997\n",
      "[Epoch:  195] cost = 1714.06665\n",
      "[Epoch:  196] cost = 1868.5\n",
      "[Epoch:  197] cost = 1953.48145\n",
      "[Epoch:  198] cost = 1814.09949\n",
      "[Epoch:  199] cost = 1864.51025\n",
      "[Epoch:  200] cost = 1742.38611\n",
      "[Epoch:  201] cost = 1728.54626\n",
      "[Epoch:  202] cost = 1766.41968\n",
      "[Epoch:  203] cost = 1786.65845\n",
      "[Epoch:  204] cost = 1679.04688\n",
      "[Epoch:  205] cost = 1887.37805\n",
      "[Epoch:  206] cost = 1694.92175\n",
      "[Epoch:  207] cost = 1588.8949\n",
      "[Epoch:  208] cost = 1813.78101\n",
      "[Epoch:  209] cost = 1736.26074\n",
      "[Epoch:  210] cost = 1673.17371\n",
      "[Epoch:  211] cost = 1600.42615\n",
      "[Epoch:  212] cost = 1601.72559\n",
      "[Epoch:  213] cost = 1594.5426\n",
      "[Epoch:  214] cost = 1574.29102\n",
      "[Epoch:  215] cost = 1588.61877\n",
      "[Epoch:  216] cost = 1507.55359\n",
      "[Epoch:  217] cost = 1637.02917\n",
      "[Epoch:  218] cost = 2171.53735\n",
      "[Epoch:  219] cost = 2934.15723\n",
      "[Epoch:  220] cost = 1926.72388\n",
      "[Epoch:  221] cost = 1771.6825\n",
      "[Epoch:  222] cost = 1595.09167\n",
      "[Epoch:  223] cost = 1634.81519\n",
      "[Epoch:  224] cost = 1510.61841\n",
      "[Epoch:  225] cost = 2054.93994\n",
      "[Epoch:  226] cost = 1596.2478\n",
      "[Epoch:  227] cost = 1718.96619\n",
      "[Epoch:  228] cost = 1556.69189\n",
      "[Epoch:  229] cost = 1795.39478\n",
      "[Epoch:  230] cost = 1491.96899\n",
      "[Epoch:  231] cost = 1485.38098\n",
      "[Epoch:  232] cost = 1512.14209\n",
      "[Epoch:  233] cost = 1502.00745\n",
      "[Epoch:  234] cost = 1620.38989\n",
      "[Epoch:  235] cost = 1538.36121\n",
      "[Epoch:  236] cost = 1564.3938\n",
      "[Epoch:  237] cost = 1510.05627\n",
      "[Epoch:  238] cost = 1609.61597\n",
      "[Epoch:  239] cost = 1437.18701\n",
      "[Epoch:  240] cost = 1557.78833\n",
      "[Epoch:  241] cost = 1521.65405\n",
      "[Epoch:  242] cost = 1458.35449\n",
      "[Epoch:  243] cost = 1648.3916\n",
      "[Epoch:  244] cost = 1441.76392\n",
      "[Epoch:  245] cost = 1801.19971\n",
      "[Epoch:  246] cost = 1613.04041\n",
      "[Epoch:  247] cost = 1602.8916\n",
      "[Epoch:  248] cost = 1361.93201\n",
      "[Epoch:  249] cost = 1404.39417\n",
      "[Epoch:  250] cost = 1460.05017\n",
      "Learning Finished~!#@\n"
     ]
    }
   ],
   "source": [
    "loss_function = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.RMSprop(model_1.parameters(), lr=learning_rate)\n",
    "batch_size = 310\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = 1240 // batch_size\n",
    "\n",
    "    for i in range(len(train_data)):\n",
    "        X = Variable(torch.FloatTensor(train_data[i]))\n",
    "        Y = Variable(torch.FloatTensor(train_label[i]))\n",
    "        optimizer.zero_grad()\n",
    "        Y_prediction = model_1(X)\n",
    "#         print(X, Y_prediction, Y)\n",
    "        loss = loss_function(Y_prediction, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost += loss / total_batch\n",
    "#         print(avg_cost)\n",
    "    print(\"[Epoch: {:>4}] cost = {:>.9}\".format(epoch+1, avg_cost.data[0]))\n",
    "\n",
    "print('Learning Finished~!#@')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate accuracy\n",
    "- 2 classes and 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 160 0.53125\n",
      "85 160 0.53125\n",
      "85 160 0.53125\n",
      "85 160 0.53125\n",
      "85 160 0.53125\n",
      "85 160 0.53125\n",
      "85 160 0.53125\n",
      "85 160 0.53125\n",
      "85 160 0.53125\n",
      "85 160 0.53125\n",
      "Accuracy: 53.125%\n"
     ]
    }
   ],
   "source": [
    "total = 160\n",
    "\n",
    "all_predict = []\n",
    "all_answer = []\n",
    "all_accu = 0\n",
    "for i in range(10):\n",
    "    correct = 0\n",
    "    for index, i in enumerate(new_data_dic['s02']['data']):\n",
    "        x_test = Variable(torch.Tensor(i).view(-1, 32*101))\n",
    "        y_test = model(x_test)\n",
    "#         print(y_test)\n",
    "        predict = []\n",
    "        answer = []\n",
    "        for j in y_test[0]:\n",
    "            if float(j)>5:\n",
    "                predict.append(1)\n",
    "            else:\n",
    "                predict.append(0)\n",
    "        for j in new_data_dic['s02']['labels'][index]:\n",
    "#             print(j)\n",
    "            if j>5:\n",
    "                answer.append(1)\n",
    "            else:\n",
    "                answer.append(0)\n",
    "#         print(predict, answer)\n",
    "        all_predict.append(predict)\n",
    "        all_answer.append(answer)\n",
    "\n",
    "    # print(np.array(all_predict).reshape(-1, 40*4), np.array(all_answer).reshape(-1, 40*4))\n",
    "\n",
    "    for i in range(len(np.array(all_predict).reshape(-1, 40*4)[0])):\n",
    "#         print(np.array(all_predict).reshape(-1, 40*4)[0][i], np.array(all_answer).reshape(-1, 40*4)[0][i])\n",
    "        if(np.array(all_predict).reshape(-1, 40*4)[0][i] == np.array(all_answer).reshape(-1, 40*4)[0][i]):\n",
    "            correct += 1\n",
    "    all_accu += correct/total\n",
    "    print(correct, total, correct/total)\n",
    "print(\"Accuracy: {}%\".format((all_accu/10) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 160 0.28125\n",
      "45 160 0.28125\n",
      "45 160 0.28125\n",
      "45 160 0.28125\n",
      "45 160 0.28125\n",
      "45 160 0.28125\n",
      "45 160 0.28125\n",
      "45 160 0.28125\n",
      "45 160 0.28125\n",
      "45 160 0.28125\n",
      "Accuracy: 28.125%\n"
     ]
    }
   ],
   "source": [
    "total = 160\n",
    "\n",
    "all_predict = []\n",
    "all_answer = []\n",
    "all_accu = 0\n",
    "for i in range(10):\n",
    "    correct = 0\n",
    "    for index, i in enumerate(new_data_dic['s02']['data']):\n",
    "        x_test = Variable(torch.Tensor(i).view(-1, 32*101))\n",
    "        y_test = model_1(x_test)\n",
    "        predict = []\n",
    "        answer = []\n",
    "        for j in y_test[0]:\n",
    "            if float(j)>6:\n",
    "                predict.append(1)\n",
    "            elif float(j) <= 6 and float(j) > 4:\n",
    "                predict.append(0)\n",
    "            else:\n",
    "                predict.append(-1)\n",
    "        for j in new_data_dic['s02']['labels'][index]:\n",
    "            if j>6:\n",
    "                answer.append(1)\n",
    "            elif j <= 6 and j>4:\n",
    "                answer.append(0)\n",
    "            else:\n",
    "                answer.append(-1)\n",
    "#         print(predict, answer)\n",
    "        all_predict.append(predict)\n",
    "        all_answer.append(answer)\n",
    "\n",
    "\n",
    "    # print(np.array(all_predict).reshape(-1, 40*4), np.array(all_answer).reshape(-1, 40*4))\n",
    "\n",
    "    for i in range(len(np.array(all_predict).reshape(-1, 40*4)[0])):\n",
    "#         print(np.array(all_predict).reshape(-1, 40*4)[0][i], np.array(all_answer).reshape(-1, 40*4)[0][i])\n",
    "        if(np.array(all_predict).reshape(-1, 40*4)[0][i] == np.array(all_answer).reshape(-1, 40*4)[0][i]):\n",
    "            correct += 1\n",
    "    all_accu += correct/total\n",
    "    print(correct, total, correct/total)\n",
    "print(\"Accuracy: {}%\".format((all_accu/10) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "the 2 classes accuracy is : 49~53% and the 3 classes accuracy is : 28~33%<br>\n",
    "before we use EEG data sets the accuracy is : 69~73%\n",
    "<img src=\"before.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
